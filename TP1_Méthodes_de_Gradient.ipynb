{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'algorithme de descente de gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Le cas d'une fonctionnelle quadratique\n",
    " \n",
    "Tout d'abord, nous appliquons la méthode à une fonctionnelle quadratique :\n",
    "\\begin{align}\\label{quadf}\\tag{1} f(x)=\\dfrac12 x^TA x + b^T x +c,\\qquad \\text{pour } x\\in \\mathbb{R}^ N, \\end{align}\n",
    "avec\n",
    "$A$ une matrice réelle $N\\times N$, symétrique définie positive, $b\\in\\mathbb{R}^N$ et $c\\in \\mathbb{R}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Calculez le gradient et la matrice Hessienne de $f$.\n",
    "\n",
    "**Question 2.** En déduire que $f$  est $\\gamma$-convexe.\n",
    "\n",
    "**Question 3.** Montrez que $f$ atteint son minimum sur $\\mathbb{R}^N$ en un seul point $x^*$. Donnez une caractérisation de ce point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 L'algorithme de descente de gradient à pas optimal\n",
    "\n",
    "Soit $f$ une fonction convexe et coercive de classe $C^1$ sur $\\mathbb{R}^N$. L'algorithme de descente de gradient à pas optimal est défini comme suit. \n",
    "\n",
    "Soit $x^0\\in \\mathbb{R}^N$ (on essaie de choisir $x^0$ proche de $x^*$, en l'absence d'indication on prend $x^0=0$). \n",
    "\n",
    "Ensuite, pour $k=0,1,2,\\ldots\\ $ jusqu'à convergence, répéter : \n",
    "\n",
    "$$\n",
    "\\left|\n",
    "\\begin{array}{lcl}\n",
    "d^k& \\longleftarrow & -\\nabla f(x^k),\\\\\n",
    "\\alpha_k &\\longleftarrow &\\mathop{argmin}_{t>0} f(x^k + td^k),\\\\ \n",
    "x^{k+1}&\\longleftarrow &x^k+\\alpha_k d^k\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Proposez un critère d'arrêt pour l'algorithme qui utilise la caractérisation de la question **3**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque :** En général, on ne sait pas calculer $\\alpha_k$ et en pratique, la deuxième étape est remplacée par une recherche approchée. Cependant, lorsque $f$ est quadratique, le calcul de $\\alpha_k$ est ``facile''. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Dans le cas de la fonction quadratique (1), explicitez $d^k$ et $\\alpha_k$ comme fonctions de $A$, $x^k$ et $b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous spécifions $N=2$ et\n",
    "$$ A=\\binom{C\\quad 0}{0\\quad 1},\\quad C\\ge 1,\\quad b=0,\\quad c=0.$$\n",
    "**Question 6.** Quel est l'infimum de $f$ sur $\\mathbb{R}^2$ dans ce cas ? Donner $x^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Deux fonctions sont données ci-dessous :\n",
    "- une fonction qui dessine un champ de vecteur donné par une application $F$. À titre d'exemple, elle est appliquée au champ de vecteurs $G(x,y)=(x, 8y)$ dans la boîte $[-8,8]\\times[-2.1,2.1]$.\n",
    "- une fonction qui dessine quelques lignes de niveau d'une fonction $f$. Elle est appliquée à $g(x,y)=\\dfrac{x^2+8x^2}2$ toujours dans la boîte $[-8,8]\\times[-2.1,2.1]$ avec 8 lignes de niveaux $g=0$, $g=4$, $\\dots$, $g=28$.\n",
    "\n",
    "Notez que $G=\\nabla g$. Qu'observez-vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def draw_vector_field(F, xmin, xmax, ymin, ymax, N=20):\n",
    "    X = np.linspace(xmin, xmax, N)  # coordonnes X et Y\n",
    "    Y = np.linspace(ymin, ymax, N)  # des points de la grille\n",
    "    U, V = F(*np.meshgrid(X, Y))  # vector field\n",
    "    M = np.hypot(U, V)  # Normes des (U[i],V[i])\n",
    "    M[M == 0] = 1  # évite la division par 0\n",
    "    U /= M  # Normalisations de U\n",
    "    V /= M  # ...  et de V\n",
    "    return plt.quiver(X, Y, U, V, angles='xy')\n",
    "\n",
    "def level_lines(f, xmin, xmax, ymin, ymax, levels, N=500):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = np.linspace(ymin, ymax, N)\n",
    "    z = f(*np.meshgrid(x, y))\n",
    "    level_l = plt.contour(x, y, z, levels=levels)\n",
    "    #plt.clabel(level_l, levels, fmt='%.1f') \n",
    "\n",
    "\n",
    "g = lambda x, y: .5*(x**2 + 8*y**2)\n",
    "G = lambda x, y: np.array([x, 8*y])\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "level_lines(g, -8, 8, -3, 3, np.linspace(0, 28, 8))\n",
    "draw_vector_field(G,  -8, 8, -3, 3, 18)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Implémentez l'algorithme de descente de gradient à pas optimal. Le point initial doit être $x^0=\\binom1C$.\n",
    "\n",
    "**Question 9.** Sur le même graphique, représentez les itérations, quelques lignes de niveau de $f$ et le champ de vecteur normalisé $\\dfrac {1}{|\\nabla f|}\\nabla f$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 8 (Algorithme de descente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 9 (Représentations graphiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** Changez la valeur de $C$ de 1 à 32 ($C=1,2,4,8,16,32$). Qu'observez-vous ?\n",
    "\n",
    "**Question 11.** Tracez le nombre d'itérations de la méthode en fonction de $C$. Faites une hypothèse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 10   (Calculs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 11  (graphiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution 11__ (Hypothèse sur le comportement de la méthode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Le cas d'une fonction convexe régulière, line search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère la fonction définie par\n",
    "$$\n",
    "f(x,y):= \\cosh(x) + \\sin^2(x+y),\\qquad \\text{pour }z=(x,y)\\in \\mathbb{R}^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.** Montrer que les minimiseurs de $f$ sont les points de la form $(0,n\\pi)$ pour $n\\in\\mathbb{Z}$.\n",
    "\n",
    "Montrer que $f$ est convexe au voisinage de $z^0_*:=(0,0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons appliquer un algorithme de descente de gradient avec ``line search'' à la fonction $f$. Plus précisément :\n",
    "\n",
    "Étant donné  $z^0=(x^0,y^0)\\in\\mathbb{R}^2$, calculer de manière récursive, jusqu'à convergence,\n",
    "\n",
    "$$\n",
    "\\left|\n",
    "\\begin{array}{lcl}\n",
    "d^k& \\longleftarrow & -\\nabla f(z^k),\\\\\n",
    "\\alpha_k &\\longleftarrow & \\text{Line-search}\\ \\left(\\ t\\mapsto f(z^k + td^k)\\ \\right),\\\\ \n",
    "z^{k+1}&\\longleftarrow &z^k+\\alpha_k d^k\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Précisons la deuxième étape. On remarque d'abord que pour $t>0$,\n",
    "\n",
    "$$\n",
    "f(z^k+t d^k) \\,=\\, f(z^k) -t \\|d^k\\|^2 +o(t).\n",
    "$$\n",
    "\n",
    "En fait, si $f$ est convexe au voisinage de $z^k$, on a aussi pour $t>0$ assez petit, \n",
    "\n",
    "$$\n",
    "f(z^k+t d^k)\\, \\ge\\, f(z^k) -t \\|d^k\\|^2,\n",
    "$$\n",
    "\n",
    "donc on ne peut pas demander $f(z^k+t d^k) \\,\\le\\, f(z^k) -t \\|d^k\\|^2$. \n",
    "\n",
    "L'idée de la *condition Armijo* est de demander un peu moins. Fixons un $c\\in (0,1)$ : la condition Armijo s'écrit : \n",
    "\n",
    "$$\n",
    "\\tag{2}f(z^k+t d^k)\\, \\le\\, f(z^k) -c\\, t \\|d^k\\|^2.\n",
    "$$\n",
    "\n",
    "En utilisant le développement limité ci dessus, on a \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "f(z^k+t d^k) &=& f(z^k) -t \\|d^k\\|^2 +o(t)\\\\\n",
    "   &=& f(z^k) -c\\, t \\|d^k\\|^2 - (1-c)t\\|d^k\\|^2 +o(t)\\\\\n",
    "   & = & f(z^k) -c\\, t \\|d^k\\|^2 -t \\left[(1-c)\\|d^k\\|^2 +o(1)\\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Pour $t>0$ assez petit, le terme entre crochet est positif et donc (2) est vrai.\n",
    "\n",
    "Nous ne voulons pourtant pas choisir un $\\alpha_k$ trop petit (l'algorithme calerait). Pour éviter cela, nous fixons un pas maximal $\\alpha_0$ et un facteur $\\beta\\in(0,1)$ et nous testons successivement (2) avec $t=\\alpha_0$, $t=\\alpha_0\\beta$, $t=\\alpha_0\\beta^2$, ... \n",
    "\n",
    "On choisi $\\alpha_k=\\alpha_0\\beta^j$ où $j$ est le premier entier tel que $t=\\alpha_0\\beta^j$ vérifie (2).\n",
    "\n",
    "Remarquez que comme $0<\\beta<1$ et que (2) est vraie pour $t>0$ assez petit, cet entier existe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13.** Implémentez la méthode ci-dessus, avec $c=0.5$, $\\beta=0.75$. Commencez par $z^0=(1,0.5)$ et $\\alpha=1$. Ensuite, pour $k\\ge 1$ utilisez $\\alpha\\leftarrow\\alpha_{k-1}/\\beta$.\n",
    "\n",
    "Tout d'abord pour vous aider, la cellule suivante montre quelques ensembles de niveaux de $f$ et le champ de vecteur normalisé $\\dfrac {1}{|\\nabla f|}\\nabla f$ au voisinage de $z^*$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector_field_2(F, xmin, xmax, ymin, ymax, N=15):\n",
    "    X = np.linspace(xmin, xmax, N)  \n",
    "    Y = np.linspace(ymin, ymax, N)\n",
    "    U, V = F(*np.meshgrid(X, Y))  # Champ de vecteur\n",
    "    M = np.hypot(U, V)  # Normes des (U[i],V[i])\n",
    "    M[M == 0] = 1  # évite la division par 0\n",
    "    U /= M  # normalisation de U\n",
    "    V /= M  # .... et de V\n",
    "    return plt.quiver(X, Y, U, V, angles='xy')\n",
    "\n",
    "def level_lines_2(f, xmin, xmax, ymin, ymax, levels, N=500):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = np.linspace(ymin, ymax, N)\n",
    "    z = f(*np.meshgrid(x, y))\n",
    "    level_l = plt.contour(x, y, z, levels=levels)\n",
    "    #plt.clabel(level_l, levels, fmt='%.1f') \n",
    "\n",
    "f = lambda x, y : np.cosh(x)+ np.sin(x + y)**2\n",
    "df = lambda x, y : np.array([np.sinh(x) \n",
    "                             + 2*np.cos(x + y)*np.sin(x + y),\n",
    "                             2*np.cos(x + y)*np.sin(x + y)])\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(9,6))\n",
    "level_lines_2(f, -1.1, 1.1, -1.1, 1.1, np.linspace(1, 3, 10))\n",
    "draw_vector_field_2(df, -1.1, 1.1, -1.1, 1.1, 10)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de f et df (i.e. : f')\n",
    "f = lambda x, y : np.cosh(x)+ np.sin(x + y)**2\n",
    "df = lambda x, y : np.array([np.sinh(x) + 2*np.cos(x + y)*np.sin(x + y), 2*np.cos(x + y)*np.sin(x + y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère maintenant la fonction définie sur $\\mathbb{R}^3$ par \n",
    "$$\n",
    "f(x,y,z):= \\cosh(x) + \\sin^2(x+y) + (y-z)^2,\\qquad \\text{pour }w=(x,y,z)\\in \\mathbb{R}^3.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14.** Appliquez la méthode d'optimisation ci-dessus à cette fonction, en commençant par $w^0=(1,0.5,1)$ (avec toujours $c=0.5$, $\\beta=0.75$ et $\\alpha=1$ à la première itération). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour les plots en 3 dimensions\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# exemple\n",
    "t = np.linspace(0,np.pi,101)\n",
    "x, y, z = np.cos(t), np.sin(t), t+.5*np.sin(t)**2\n",
    "\n",
    "ax = Axes3D(plt.figure())  # Define the 3D plot\n",
    "ax.set(xlabel=r'$x$', ylabel=r'$y$', zlabel=r'$z$')\n",
    "ax.plot(x, y, z,'.')  # Plot of the trajectory\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de f et df (i.e. : f')\n",
    "f = lambda w : np.cosh(\n",
    "    w[0])+ np.sin(w[0] + w[1])**2 + (w[1] - w[2])**2\n",
    "df = lambda w : np.array(\n",
    "    [np.sinh(w[0]) + 2*np.cos(w[0] + w[1])*np.sin(w[0] + w[1]), \n",
    "     2*np.cos(w[0] + w[1])*np.sin(w[0] + w[1]) + 2*(w[1] - w[2]), \n",
    "     2*(w[2] - w[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 14 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
